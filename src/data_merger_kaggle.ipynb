{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee3ea90-e254-41df-8e79-0aa8e013cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/parthshah/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import kaggle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a24359b-6bb9-4ab2-8e85-3d1b070c103e",
   "metadata": {},
   "source": [
    "## Download dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9216fa-1739-4000-8ffb-21edef4404c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/parthshah/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/shahp7575/reddit-posts-with-keyword-coffee/versions/\n",
      "License(s): MIT\n",
      "Downloading reddit-posts-with-keyword-coffee.zip to kaggle_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41.7M/41.7M [00:01<00:00, 25.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_path = \"kaggle_dataset/\"\n",
    "dataset_slug = \"shahp7575/reddit-posts-with-keyword-coffee/\"\n",
    "os.system(f'kaggle datasets download -d {dataset_slug} -p {download_path} --unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "289c81b5-ffc8-413c-a284-4755521f93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the file present in kaggle_dataset directory first, then run the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d6f90-37eb-4e53-b9b5-f68f96c32daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def pull_push_kaggle(dataset_slug: str, download_kaggle_path: str, download_scraped_path: str):\n",
    "\n",
    "    # Ensure the download path is fresh\n",
    "    if os.path.exists(download_kaggle_path):\n",
    "        shutil.rmtree(download_kaggle_path)\n",
    "    os.makedirs(download_kaggle_path, exist_ok=True)\n",
    "    \n",
    "    # download existing dataset\n",
    "    os.system(f'kaggle datasets download -d {dataset_slug} -p {download_kaggle_path} --unzip')\n",
    "\n",
    "    # read downloaded dataset, if exists\n",
    "    kaggle_csv = glob.glob(download_kaggle_path + \"*.csv\")[0]\n",
    "    print(kaggle_csv)\n",
    "\n",
    "    df_kaggle = pd.read_csv(kaggle_csv)\n",
    "    print(\"Kaggle CSV shape: \", df_kaggle.shape)\n",
    "\n",
    "    # read scraped dataset\n",
    "    CSV_FILES = glob.glob(download_scraped_path + \"*.csv\")\n",
    "    print(\"Total CSV files scraped: \", len(CSV_FILES))\n",
    "    df_list = []\n",
    "    for f in CSV_FILES:\n",
    "        df = pd.read_csv(f)\n",
    "        df_list.append(df)\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"Scraped CSV files shape: \", combined_df.shape)\n",
    "\n",
    "    # append scraped data to downloaded kaggle data\n",
    "    df_final = pd.concat([df_kaggle, combined_df], ignore_index=True)\n",
    "    df_final.drop_duplicates(inplace=True)\n",
    "    print(\"Appended data shape: \", df_final.shape)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DATASET_SLUG = \"shahp7575/reddit-posts-with-keyword-coffee/\"\n",
    "    DOWNLOAD_KAGGLE_PATH = \"kaggle_downloaded_dataset/\"\n",
    "    DOWNLOAD_SCRAPED_PATH = \"data/\"\n",
    "\n",
    "    pull_push_kaggle(dataset_slug=DATASET_SLUG, \n",
    "                     download_kaggle_path=DOWNLOAD_KAGGLE_PATH,\n",
    "                     download_scraped_path=DOWNLOAD_SCRAPED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cce2a2-9249-49bb-b96c-a1eb486fa374",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_csv = glob.glob(download_path + \"*.csv\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69a9020-3145-48d7-b46f-deb8da84dd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kaggle_dataset/reddit_coffee_scraper_till_2024-11-13 041137.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9067d0-e204-4dba-a900-9c249683927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kaggle = pd.read_csv(kaggle_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3154c42-ebd3-4e4f-978f-02a408c00e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66826, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296b07e-6ad7-4f39-996f-08076b97a353",
   "metadata": {},
   "source": [
    "## Read Scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5609b792-749d-4f70-aae2-2e47d124727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "CSV_FILES = glob.glob(DATA_PATH + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1661e481-b4f7-4fae-a4f0-f1b4d576f131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/reddit_coffee_posts_1737792601_1737799801.csv',\n",
       " '../data/reddit_coffee_posts_1733408060_1733415260.csv',\n",
       " '../data/reddit_coffee_posts_1734776286_1734783486.csv',\n",
       " '../data/reddit_coffee_posts_1731852703_1731859903.csv',\n",
       " '../data/reddit_coffee_posts_1733826123_1733833323.csv',\n",
       " '../data/reddit_coffee_posts_1737900670_1737907870.csv',\n",
       " '../data/reddit_coffee_posts_1735070987_1735078187.csv',\n",
       " '../data/reddit_coffee_posts_1737987221_1737994421.csv',\n",
       " '../data/reddit_coffee_posts_1736636142_1736643342.csv',\n",
       " '../data/reddit_coffee_posts_1738131253_1738138453.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_FILES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b4759a-5b7a-4ef5-9528-478cab71e510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CSV_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472658f5-93f8-484a-9baf-7d87603a2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fb15d35-ae7f-49a4-9803-c8866cbf0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in CSV_FILES:\n",
    "    df = pd.read_csv(f)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed0224a-6aad-486b-9ae5-48d909329c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031eb03f-7931-470e-a3bc-c9da75d91e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145237, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc9c9f5-6dc7-4890-aa0a-390d98405efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140520</th>\n",
       "      <td>1hvss15</td>\n",
       "      <td>https://www.reddit.com/r/Dhaka/comments/1hvss1...</td>\n",
       "      <td>What do i do now?</td>\n",
       "      <td>During my exam time i have been facing many pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.736261e+09</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86424</th>\n",
       "      <td>1hyyopm</td>\n",
       "      <td>https://www.reddit.com/r/lithuania/comments/1h...</td>\n",
       "      <td>Thank you Lithuania</td>\n",
       "      <td>Hi, I am a German officer currently stationed ...</td>\n",
       "      <td>121</td>\n",
       "      <td>1.736611e+09</td>\n",
       "      <td>lithuania</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                                url  \\\n",
       "140520  1hvss15  https://www.reddit.com/r/Dhaka/comments/1hvss1...   \n",
       "86424   1hyyopm  https://www.reddit.com/r/lithuania/comments/1h...   \n",
       "\n",
       "                       title  \\\n",
       "140520    What do i do now?    \n",
       "86424   Thank you Lithuania    \n",
       "\n",
       "                                                     text  score  \\\n",
       "140520  During my exam time i have been facing many pr...      1   \n",
       "86424   Hi, I am a German officer currently stationed ...    121   \n",
       "\n",
       "         created_utc  subreddit  num_comments  upvote_ratio  over_18  \n",
       "140520  1.736261e+09      Dhaka             0          0.99    False  \n",
       "86424   1.736611e+09  lithuania             8          0.98    False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13a979-b7f8-4678-b574-02b28de7a3fe",
   "metadata": {},
   "source": [
    "## Merge Scraped data with Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2542a5e4-f140-4349-b1a8-7f5b7f1ccc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_kaggle, combined_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6257633-3cfa-4469-a89c-6b49234ad8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212063, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9449d70-413b-4cdc-b90f-861aca563253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-04 00:02:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/b8fsbws114377d5kxxk54hdm0000gn/T/ipykernel_65160/1628956749.py:2: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  max_datetime = datetime.strftime(datetime.utcfromtimestamp(max_utc), \"%Y-%m-%d %H:%m:%S\")\n"
     ]
    }
   ],
   "source": [
    "max_utc = df_final['created_utc'].max()\n",
    "max_datetime = datetime.strftime(datetime.utcfromtimestamp(max_utc), \"%Y-%m-%d %H:%m:%S\")\n",
    "print(max_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2bfde9b-306e-496b-bf58-a84d787befab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43660f83-7bab-4a2f-9a79-6efec01a8401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210779, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe69c66-bfb7-467a-8447-1f9397eb5cc0",
   "metadata": {},
   "source": [
    "## Upload to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b05ceba2-010d-47d6-a0f5-29f9ad06d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_coffee_scraper_till_2025-02-04 00:02:41\n"
     ]
    }
   ],
   "source": [
    "version_name = f\"reddit_coffee_scraper_till_{max_datetime}\"\n",
    "print(version_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b562f8a1-92ba-4b52-b86b-40207f06b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(f\"kaggle_dataset/{version_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d18a2ca-e942-41b9-8bca-7b2d5d1a147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the old versions from the directory kaggle_dataset/ first, then run below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02cfa218-e63f-4af8-a1f7-07a927b06f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/parthshah/.kaggle/kaggle.json'\n",
      "Starting upload for file reddit_coffee_scraper_till_2025-02-04 00:02:41.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352M/352M [01:35<00:00, 3.89MB/s] \n",
      "  0%|          | 0.00/285 [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: reddit_coffee_scraper_till_2025-02-04 00:02:41.csv (352MB)\n",
      "Starting upload for file .ipynb_checkpoints.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [00:00<00:00, 515B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful: .ipynb_checkpoints.zip (285B)\n",
      "Dataset version is being created. Please check progress at https://www.kaggle.com/shahp7575/reddit-posts-with-keyword-coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'kaggle datasets version -p kaggle_dataset/ -m \"New data upload - {version_name}\" --dir-mode zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f97bf93-fbbf-4962-8516-da784d8c21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data successfully uploaded on kaggle.\n",
    "# next, delete the file from kaggle_dataset\n",
    "# delete all files from data/, except one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9965b230-060d-4f76-9d2b-eef8e53804ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f21e4-0a81-47fe-83a5-666aee03371e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edc5a1-b9d7-4365-b8d4-42c2b11c24cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711bf7a-494f-43bb-a50d-956aeb7b072e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ce265-d9cc-4b07-bb52-8f227d663947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a1852-297e-4741-bbbd-65bbf56d924b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coffee Scraper Kernel",
   "language": "python",
   "name": "coffee_scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
